# Hierarchical Breakout experiment draft using option-based control
experiment:
  name: breakout_hier_options
  seed: 777
  total_timesteps: 3000000
  eval_interval: 100000
  save_interval: 250000
  progress_bar: true
  notes: "Two-level controller: manager selects skills, low-level skills drive paddle/ball behaviors"

environment:
  id: ALE/Breakout-v5
  frame_skip: 4
  frame_stack: 4
  terminate_on_life_loss: true

model:
  algo: hierarchical
  n_envs: 1
  vec_env_class: dummy

hierarchical:
  manager:
    horizon: 32
    update_interval: 8
    gamma: 0.99
    intrinsic_reward_scale: 0.1
    advantage_target: delta
    temperature: 0.8
  skills:
    - name: track_ball
      trigger: "ball_in_play"
      horizon: 16
      success_reward: 0.5
      failure_penalty: -0.2
      termination_on_success: false
      warmup_steps: 20000
    - name: serve_setup
      trigger: "pre_serve"
      horizon: 12
      success_reward: 1.0
      failure_penalty: -0.5
      termination_on_success: true
      warmup_steps: 10000
    - name: tunnel_push
      trigger: "left_tunnel"
      horizon: 24
      success_reward: 1.5
      failure_penalty: -0.3
      termination_on_success: true
      warmup_steps: 30000

training:
  buffer_size: 100000
  batch_size: 64
  learning_rate: 0.00025
  gamma: 0.99
  target_update_interval: 2000
  epsilon_start: 1.0
  epsilon_end: 0.05
  epsilon_decay_steps: 1000000
  manager_learning_rate: 0.00025
  manager_epsilon_start: 1.0
  manager_epsilon_end: 0.05
  manager_epsilon_decay_steps: 1500000
  gradient_updates_per_step: 1
  eval_games: 10

hardware:
  device: auto
  num_threads: 4
  mps_fallback: true

logging:
  tensorboard_log: runs/tensorboard
  checkpoint_dir: runs/checkpoints
  monitor_dir: runs/monitor
  video_dir: runs/videos
  verbose: 1
  log_interval: 100

# Note: hierarchical training loop is under construction (see src/simple_game/hierarchical/).
# Run once HierarchicalTrainer.train is fully implemented.
